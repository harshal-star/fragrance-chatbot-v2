{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8768427d",
   "metadata": {},
   "source": [
    "RAG\n",
    "1. New model testing\n",
    "2. RAG performance comparison across models\n",
    "3. Adding new data types to rag pipeline\n",
    "\n",
    "KNOWLEDGE BASES\n",
    "1. ALL THE THINGS I DO\n",
    "\n",
    "APPLICATIONS\n",
    "1. Set up the templates - Assisted Builder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c5f32f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "def load_table_as_dataframe(db_path, table_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    try:\n",
    "        # Use pandas to read the table into a DataFrame\n",
    "        df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading table '{table_name}':\", e)\n",
    "        return None\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    db_path = \"C:/startup/client_work/fragrance_chatbot_v2/fragrance_chatbot.db\"\n",
    "    table_name = \"sessions\"  # Replace with your actual table name\n",
    "    df = load_table_as_dataframe(db_path, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c6ea2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_29av8q8rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ba660d60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df[df[\"user_id\"] == \"user_fe56xu4ci\"][\"conversation_history\"].values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a422fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"user_id\"] == \"user_fe56xu4ci\"][\"session_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cb8ebc89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>conversation_history</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [session_id, user_id, conversation_history, created_at, updated_at]\n",
       "Index: []"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "371e5f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"messages\": [{\"role\": \"assistant\", \"content\": \"Hey hey! \\\\ud83c\\\\udf1f I\\\\u2019m Lila, your cozy fragrance stylist buddy. So happy you\\'re here! Can\\\\u2019t wait to dive into the world of scents with you. \\\\n\\\\nAnyway! What\\'s your name?\", \"timestamp\": \"2025-05-17T09:49:48.593270\"}]}'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"conversation_history\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98753902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows deleted from table 'sessions'.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def delete_all_rows_from_table(db_path, table_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Delete all rows from the table\n",
    "        cursor.execute(f\"DELETE FROM {table_name}\")\n",
    "        conn.commit()\n",
    "        print(f\"All rows deleted from table '{table_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting rows from table '{table_name}':\", e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    db_path = \"C:/startup/client_work/fragrance_chatbot_v2/fragrance_chatbot.db\"\n",
    "    table_name = \"sessions\"  # Replace with your actual table name\n",
    "    delete_all_rows_from_table(db_path, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6ac6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5051ef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 tables in the database:\n",
      "1. chat_history\n",
      "2. sessions\n",
      "3. users\n",
      "4. user_profiles\n",
      "5. scent_preferences\n",
      "6. style_preferences\n",
      "7. personality_traits\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def list_tables(db_path):\n",
    "    \"\"\"\n",
    "    Connect to a SQLite database and list all tables in it.\n",
    "    \n",
    "    Args:\n",
    "        db_path (str): Path to the SQLite database file\n",
    "    \n",
    "    Returns:\n",
    "        list: List of table names\n",
    "    \"\"\"\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"Error: Database file '{db_path}' not found.\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Query to get all tables\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        # Close connection\n",
    "        conn.close()\n",
    "        \n",
    "        # Extract table names from results\n",
    "        table_names = [table[0] for table in tables]\n",
    "        \n",
    "        # Print results\n",
    "        if table_names:\n",
    "            print(f\"Found {len(table_names)} tables in the database:\")\n",
    "            for i, table in enumerate(table_names, 1):\n",
    "                print(f\"{i}. {table}\")\n",
    "        else:\n",
    "            print(\"No tables found in the database.\")\n",
    "            \n",
    "        return table_names\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQLite error: {e}\")\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     db_path = input(\"Enter the path to your sessions.db file: \")\n",
    "    tables = list_tables(\"C:/startup/client_work/fragrance_chatbot_v2/fragrance_chatbot.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30627d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2392fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  \n",
    "\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "def _encode_image(img, file_identifier):\n",
    "    buffer = io.BytesIO()\n",
    "    file_extension = Path(file_identifier).suffix.lower()\n",
    "    if file_extension in ['.jpg', '.jpeg']:\n",
    "        img = img.convert('RGB')\n",
    "        img_format = 'PNG'\n",
    "    else:\n",
    "        img_format = 'PNG'\n",
    "    img.save(buffer, format=img_format)\n",
    "    buffer.seek(0)\n",
    "    return base64.b64encode(buffer.read()).decode('utf-8')\n",
    "\n",
    "async def _make_openai_call(base64_image):\n",
    "    \"\"\"Make API call to OpenAI Vision model.\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"extract all the details present in the image\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        \"detail\": \"high\"\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    params = {\n",
    "        \"seed\": 25,\n",
    "        \"stream\": True,\n",
    "        \"messages\": messages,\n",
    "        \"model\": \"gpt-4o-2024-08-06\",  # Using the vision model directly\n",
    "        \"timeout\": 60,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        buffer = \"\"\n",
    "        response = await client.chat.completions.create(**params)\n",
    "        async for chunk in response:\n",
    "            if chunk.choices and chunk.choices[0].delta.content is not None:\n",
    "                current_chunk = chunk.choices[0].delta.content\n",
    "                buffer += current_chunk\n",
    "\n",
    "        return buffer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error making OpenAI call: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c4d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "file_identifier = r\"C:\\harshal_documents\\photo_1.jpg\"\n",
    "# Open the image using PIL\n",
    "with Image.open(file_identifier) as img:\n",
    "    base64_image = _encode_image(img, file_identifier)\n",
    "\n",
    "# Get analysis from OpenAI\n",
    "analysis_text = await _make_openai_call(base64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dfef435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a person with short black hair and facial hair, wearing a light blue and white checkered shirt. The background is plain white. No other details or text are present in the image.\n"
     ]
    }
   ],
   "source": [
    "print(analysis_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1db8835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, AsyncGenerator\n",
    "import logging\n",
    "# from app.core.config import settings, Settings\n",
    "import io\n",
    "from pathlib import Path\n",
    "import base64\n",
    "from PIL import Image\n",
    "import json\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Image analysis prompts\n",
    "IMAGE_EXTRACTION_PROMPT = \"\"\"\n",
    "Analyze this image of a person and provide insights about their:\n",
    "1. Style and fashion preferences\n",
    "2. Personality traits (based on appearance and style)\n",
    "3. Color preferences\n",
    "4. Overall aesthetic\n",
    "\n",
    "Format the response as a JSON object with the following structure:\n",
    "{\n",
    "    \"style_analysis\": {\n",
    "        \"fashion_style\": \"string\",\n",
    "        \"color_preferences\": [\"string\"],\n",
    "        \"aesthetic\": \"string\"\n",
    "    },\n",
    "    \"personality_traits\": [\"string\"],\n",
    "    \"fragrance_recommendations\": {\n",
    "        \"scent_families\": [\"string\"],\n",
    "        \"notes\": [\"string\"],\n",
    "        \"intensity\": \"string\"\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "class LLMService:\n",
    "    def __init__(self):\n",
    "        self.client = AsyncOpenAI()\n",
    "\n",
    "    def _encode_image(self, img, file_identifier):\n",
    "        buffer = io.BytesIO()\n",
    "        file_extension = Path(file_identifier).suffix.lower()\n",
    "        if file_extension in ['.jpg', '.jpeg']:\n",
    "            img = img.convert('RGB')\n",
    "            img_format = 'PNG'\n",
    "        else:\n",
    "            img_format = 'PNG'\n",
    "        img.save(buffer, format=img_format)\n",
    "        buffer.seek(0)\n",
    "        return base64.b64encode(buffer.read()).decode('utf-8')\n",
    "\n",
    "    async def _make_openai_call(self, base64_image):\n",
    "        \"\"\"Make API call to OpenAI Vision model.\"\"\"\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"extract all the details present in the image\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        params = {\n",
    "            \"seed\": 25,\n",
    "            \"stream\": True,\n",
    "            \"messages\": messages,\n",
    "            \"model\": \"gpt-4o-2024-08-06\",  # Using the vision model directly\n",
    "            \"timeout\": 60,\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            buffer = \"\"\n",
    "            response = await self.client.chat.completions.create(**params)\n",
    "            async for chunk in response:\n",
    "                if chunk.choices and chunk.choices[0].delta.content is not None:\n",
    "                    current_chunk = chunk.choices[0].delta.content\n",
    "                    buffer += current_chunk\n",
    "            \n",
    "            return buffer\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error making OpenAI call: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    async def analyze_image(self, file_identifier: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze an image and extract style and personality information.\"\"\"\n",
    "        try:\n",
    "#             # Create a temporary directory if it doesn't exist\n",
    "#             temp_dir = Path(\"temp\")\n",
    "#             temp_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "#             # Generate a unique filename\n",
    "#             file_identifier = temp_dir / f\"uploaded_image_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "            \n",
    "#             # Decode base64 and save the image\n",
    "#             image_bytes = base64.b64decode(image_data)\n",
    "#             with open(file_identifier, \"wb\") as f:\n",
    "#                 f.write(image_bytes)\n",
    "            \n",
    "            # Open the image using PIL\n",
    "            with Image.open(file_identifier) as img:\n",
    "                base64_image = self._encode_image(img, file_identifier)\n",
    "            \n",
    "            # Get analysis from OpenAI\n",
    "            analysis_text = await self._make_openai_call(base64_image)\n",
    "            print(30 * \"----------\")\n",
    "            print(\"IMAGE ANALYSIS TEXT: \", analysis_text)\n",
    "            print(30 * \"----------\")\n",
    "            \n",
    "            # Create a natural language response\n",
    "            chat_response = f\"I've analyzed your image, and I'm excited to share what I see! {analysis_text} Let's use these insights to create a fragrance that truly reflects your unique style and personality. Would you like to tell me more about yourself?\"\n",
    "            \n",
    "            # Clean up the temporary file\n",
    "            # file_identifier.unlink()\n",
    "            \n",
    "            return {\n",
    "                \"analysis\": analysis_text,\n",
    "                \"chat_response\": chat_response\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing image: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _generate_chat_response(self, analysis: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate a natural language response from the analysis.\"\"\"\n",
    "        style = analysis[\"style_analysis\"]\n",
    "        personality = analysis[\"personality_traits\"]\n",
    "        fragrance = analysis[\"fragrance_recommendations\"]\n",
    "        \n",
    "        response = (\n",
    "            f\"Based on your style and appearance, I can see you have a {style['fashion_style']} fashion sense \"\n",
    "            f\"with a preference for {', '.join(style['color_preferences'])} colors. \"\n",
    "            f\"Your overall aesthetic is {style['aesthetic']}. \"\n",
    "            f\"\\n\\n\"\n",
    "            f\"You seem to have {', '.join(personality)} personality traits, which is wonderful! \"\n",
    "            f\"\\n\\n\"\n",
    "            f\"Based on this, I would recommend fragrances with {', '.join(fragrance['scent_families'])} notes, \"\n",
    "            f\"particularly featuring {', '.join(fragrance['notes'])}. \"\n",
    "            f\"A {fragrance['intensity']} intensity would suit you perfectly. \"\n",
    "            f\"\\n\\n\"\n",
    "            f\"Would you like me to suggest some specific fragrances that match this profile?\"\n",
    "        )\n",
    "        \n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65a9cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_service = LLMService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd487eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "IMAGE ANALYSIS TEXT:  The image shows a person with short black hair and facial hair, wearing a light blue and white checkered shirt. There are no visible text or other details present in the image.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'analysis': 'The image shows a person with short black hair and facial hair, wearing a light blue and white checkered shirt. There are no visible text or other details present in the image.',\n",
       " 'chat_response': \"I've analyzed your image, and I'm excited to share what I see! The image shows a person with short black hair and facial hair, wearing a light blue and white checkered shirt. There are no visible text or other details present in the image. Let's use these insights to create a fragrance that truly reflects your unique style and personality. Would you like to tell me more about yourself?\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_identifier = r\"C:\\harshal_documents\\photo_1.jpg\"\n",
    "await llm_service.analyze_image(file_identifier = file_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a0375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "startup_work",
   "language": "python",
   "name": "startup_work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
